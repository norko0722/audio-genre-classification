# -*- coding: utf-8 -*-
"""genre_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NR8BG4m-NentvayUlB5uFHuXDpiGvX6L
"""

import os # list of directories
import librosa # loading the data and extraction of functions
import numpy as np # working with numeric data
import pandas as pd # DataFrames
from pathlib import Path # working with path for
from tqdm.notebook import tqdm # progress bar in Colab

from google.colab import drive # import of dataset from my Google Disc on Google Colab
drive.mount('/content/drive') # directory path in Google Disc

from sklearn.model_selection import train_test_split, cross_val_score

from sklearn.preprocessing import LabelEncoder, StandardScaler  # Import StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from xgboost import XGBClassifier, plot_importance
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import accuracy_score, classification_report

audio_path = Path("/content/drive/MyDrive/genres/genres") # variable with path to particular .wav audio file

genres = [f for f in os.listdir(audio_path) if os.path.isdir(os.path.join(audio_path, f))] # list of genre directories

print("genres found: ", genres) # print list of genres found in directory

# features_data = [] # initialization of empty list for future data write

X = []  # list, where are stored number informations about song ( tempo, loudness, tone pitch ), in easy way features
y = []  # list of genres

# loop for list of genres, where genres is list of directories
for genre in genres:
    genre_dir = os.path.join(audio_path, genre) # makes full path for actual genre, for example "blues"
    # Ensure it processes .wav files only
    audio_files = [f for f in os.listdir(genre_dir) if f.endswith('.wav') and not f.startswith('._')]  # list comprehension, reach full path for actual genre
    for file in audio_files:  # loop, where file is every .wav audio file in genre directory
        print(f"Processing audio file: {file} from genre: {genre}")
        file_path = os.path.join(genre_dir, file) # crete full path for actual .wav audio file
        try:
            # Load the audio file
            # audio -> NumPy array with sample of wave sound in numbers
            # sr -> sample rate, sr=None means it use original sample rate
            audio, sr = librosa.load(file_path, sr=None)

            # Extract MFCC features using librosa
            # MFCC -> Mel-frequency Cepstral Coefficients: convert raw sound signal into number vector
            # sound features easy explained
            # y=audio -> input sound wave
            # sr -> sample rate
            # n_mfcc=13 -> calculate 13 mfcc coefficients
            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13) # matrix, 13 lines of MFCC coefficients, rows are time scope
            mfccs_mean = np.mean(mfccs.T, axis=0)  # make matrix transpose ( exchange lines and rows ) Get mean of MFCC features
            # print(f"MFCC shape: {mfccs}")
            # print(f"MFCC mean shape: {mfccs_mean}")

            # Chroma features
            chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
            chroma_mean = np.mean(chroma.T, axis=0)

            # Spectral Contrast
            spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)
            spectral_contrast_mean = np.mean(spectral_contrast.T, axis=0)

            # Zero-Crossing Rate
            zcr = librosa.feature.zero_crossing_rate(y=audio)
            zcr_mean = np.mean(zcr.T, axis=0)

            # Root Mean Square Energy
            rmse = librosa.feature.rms(y=audio)
            rmse_mean = np.mean(rmse.T, axis=0)

            # Spectral Centroid
            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)
            spectral_centroid_mean = np.mean(spectral_centroid.T, axis=0)

            # Spectral Bandwidth
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)
            spectral_bandwidth_mean = np.mean(spectral_bandwidth.T, axis=0)

            # Spectral Flatness
            spectral_flatness = librosa.feature.spectral_flatness(y=audio)
            spectral_flatness_mean = np.mean(spectral_flatness.T, axis=0)

            # Tonnetz
            tonnetz = librosa.feature.tonnetz(y=audio, sr=sr)
            tonnetz_mean = np.mean(tonnetz.T, axis=0)

            # Combine features into a single feature vector
            # One long number vector with every average feature values
            features = np.concatenate((
                mfccs_mean, chroma_mean, spectral_contrast_mean,
                zcr_mean, rmse_mean, spectral_centroid_mean,
                spectral_bandwidth_mean, spectral_flatness_mean,
                tonnetz_mean
            ))

            # Append features and corresponding label
            X.append(features)  # Append to list
            y.append(genre)     # Store the genre as the label

        except Exception as e:
            print(f"Error loading {file}: {e}")  # Catch and print any errors during file loading

# Convert lists to numpy arrays after processing all files
X = np.array(X)  # Convert to numpy array
y = np.array(y)  # Convert to numpy array

# Check if X and y are populated correctly
print(f"Number of feature vectors: {len(X)}")
print(f"Number of labels: {len(y)}")


if len(X) > 0:
    print(f"Sample features: {X[0]}")
    print(f"Sample label: {y[0]}")

# Split the data into training and testing sets
# test_size=0.2 -> 20% data will be used in test sets, rest will be used in traning sets
# random_state=42 -> ensures every data divide same way after starting the code
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the features using StandardScaler
scaler = StandardScaler() #
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Label encode the genre labels
# labels are converted to numeric labels using Label Encoder
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)